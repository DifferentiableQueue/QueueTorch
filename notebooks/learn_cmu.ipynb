{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d011fd-0c4f-419e-9079-1b873f491bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d910e1-3bc6-416e-bc76-5aa5fc0eeb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions.one_hot_categorical as one_hot_sample\n",
    "\n",
    "import queuetorch.env as env\n",
    "from queuetorch.env import QueuingNetwork\n",
    "import yaml\n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562812d-b71b-411c-ae18-9002a449ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'multiclass'\n",
    "with open(f'./configs/env/{name}.yaml', 'r') as f:\n",
    "    env_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591a62c-7f55-4343-813b-50363392e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq = env.load_env(env_config, temp = 0.1, batch = 1, seed = 23, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95070c2c-73da-4b30-9e4a-e581d13db420",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq.h = torch.tensor([1.]*5)\n",
    "dq.mu = torch.tensor([[[1. + 0.1*i for i in range(1,6)]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c33a33-a69c-4b6b-a5a7-51bddef3ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dq.h)\n",
    "print(dq.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a341c0-2ca1-4f4e-b090-88df65e65694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "priority = torch.zeros((1,dq.q)).float()\n",
    "sum_priority = priority.clone()\n",
    "\n",
    "train_seed = 42\n",
    "\n",
    "priority.requires_grad = True\n",
    "alpha = 0.1\n",
    "num_iter = 50\n",
    "st_steps = [priority.detach()]\n",
    "avg_iterate = [sum_priority.clone()]\n",
    "num = 1\n",
    "\n",
    "\n",
    "for i in range(num_iter):\n",
    "    # Calculate gradient\n",
    "    dq = env.load_env(env_config, temp = 0.00001, batch = 1, seed = 23, device = 'cpu')\n",
    "    dq.h = torch.tensor([1.]*5)\n",
    "    dq.mu = torch.tensor([[[1. + 0.1*i for i in range(1,6)]]])\n",
    "\n",
    "    if i > 0:\n",
    "        obs, state = dq.reset(seed = train_seed, init_queues = init_queues)\n",
    "    else:\n",
    "        obs, state = dq.reset(seed = train_seed)\n",
    "    total_cost = torch.tensor([[0.]]*dq.batch)\n",
    "    \n",
    "    \n",
    "    for _ in trange(1000):\n",
    "        queues, time = obs\n",
    "        \n",
    "        pr = F.softmax(priority.repeat(dq.batch,dq.s,1), -1) * dq.network\n",
    "        pr = torch.minimum(pr, queues.unsqueeze(1).repeat(1, dq.s, 1))\n",
    "        pr += 1*torch.all(pr == 0., dim = 2).reshape(dq.batch,dq.s,1) * dq.network\n",
    "        pr /= torch.sum(pr, dim = -1).reshape(dq.batch, dq.s, 1) \n",
    "        \n",
    "        action = pr\n",
    "        obs, state, cost, event_time = dq.step(state, action)\n",
    "        total_cost += cost\n",
    "\n",
    "    init_queues = queues.detach()\n",
    "    avg_cost = torch.mean(total_cost / state.time)\n",
    "    avg_cost.backward()\n",
    "\n",
    "    print(f'priority: {priority}')\n",
    "    print(f'avg_cost: {avg_cost}')\n",
    "\n",
    "    normalized_grad = priority.grad / torch.linalg.norm(priority.grad)\n",
    "    #normalized_grad = priority.grad\n",
    "    \n",
    "    priority = priority.detach() - alpha * normalized_grad\n",
    "    print(f'grad: {normalized_grad}')\n",
    "    print()\n",
    "    \n",
    "    st_steps.append(priority.detach())\n",
    "    sum_priority += priority.detach()\n",
    "    num += 1\n",
    "    avg_iterate.append(sum_priority.clone() / num)\n",
    "    \n",
    "    priority.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c55e0-f203-4f56-9563-a8d7b87e948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_steps_l = torch.stack(avg_iterate)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a7c50-9988-4050-862e-7f69543038e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "plt.style.use('seaborn-v0_8-white')\n",
    "plt.bar([f'{i}' for i in range(1,1+len(st_steps_l[k]))], st_steps_l[k], color = 'orangered', label = 'Pathwise (B = 1)')\n",
    "plt.axhline(0, color = 'black')\n",
    "plt.ylabel(r'Policy Score $\\theta_{j}$', fontsize = 20)\n",
    "plt.xlabel('Queue', fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.legend(fontsize = 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./plot/cmu_bar_q_5_value.png',dpi = 300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
